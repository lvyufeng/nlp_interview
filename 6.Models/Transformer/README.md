1. Transformer的时间复杂度
2. 为什么transformer块有LayerNorm而不是BatchNorm？
3. 为什么transformer的性能优于LSTM？
4. Transformer中最常用的是哪个层？