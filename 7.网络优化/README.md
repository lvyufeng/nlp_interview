1. **正则化你用过吗，有哪些正则化方法**
2. ReLu有什么问题？
3. Adam优化算法的局限性是什么？
4. AdamW和Adam有什么不同？
5. 我们能用大批量训练一个模型更快吗？
6. 举一个调度学习率策略的例子？ 
7. 深度学习是否应该做交叉验证？
8. BatchNorm和LayerNorm的区别？BatchNorm-计算每层的平均值和var 分层Norm-独立计算每个层的每个样本的平均值和var 为什么变压器块有LayerNorm而不是BatchNorm？
9. 

